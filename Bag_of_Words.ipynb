{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnvENEkoYqYd8hi7dWUa2X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jiaye39/TimeSeriesAnalysis/blob/main/Bag_of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words\n",
        "We study 2 types of BoW vectors:\n",
        "* **Raw Count**: actually count the number of occurences of each word in a text\n",
        "* **TF-IDF**: adjust the raw count to favor words that appear a lot in a few documents, as opposed to those who appear a lot in all documents"
      ],
      "metadata": {
        "id": "2rGDMt-GD26_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic import"
      ],
      "metadata": {
        "id": "XUC_VyfeziZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_6kius3yORa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Corpus"
      ],
      "metadata": {
        "id": "0cZrFf_-zbDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r=requests.get('https://sherlock-holm.es/stories/plain-text/scan.txt')\n",
        "\n",
        "assert r.status_code == 200\n",
        "\n",
        "with open('scandal_in_bohemia.txt', 'w') as out:\n",
        "    out.write(r.content.decode('utf-8'))\n",
        "lines = [txt for txt in open('scandal_in_bohemia.txt') if len(txt.strip()) > 0]\n",
        "\n",
        "print(lines[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO72L4gxzap3",
        "outputId": "e0cfcd93-ea25-4117-cf1f-306725f7a047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['                              A SCANDAL IN BOHEMIA\\n', '                               Arthur Conan Doyle\\n', '                                Table of contents\\n', '                                     Chapter 1\\n', '                                     Chapter 2\\n', '                                     Chapter 3\\n', '          CHAPTER I\\n', '     To Sherlock Holmes she is always the woman. I have seldom heard him\\n', '     mention her under any other name. In his eyes she eclipses and\\n', '     predominates the whole of her sex. It was not that he felt any\\n', '     emotion akin to love for Irene Adler. All emotions, and that one\\n', '     particularly, were abhorrent to his cold, precise but admirably\\n', '     balanced mind. He was, I take it, the most perfect reasoning and\\n', '     observing machine that the world has seen, but as a lover he would\\n', '     have placed himself in a false position. He never spoke of the softer\\n', '     passions, save with a gibe and a sneer. They were admirable things\\n', \"     for the observer--excellent for drawing the veil from men's motives\\n\", '     and actions. But for the trained reasoner to admit such intrusions\\n', '     into his own delicate and finely adjusted temperament was to\\n', '     introduce a distracting factor which might throw a doubt upon all his\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define First Paragraph\n",
        "par=''.join([x.strip() for x in lines[7:25]])"
      ],
      "metadata": {
        "id": "LiDjdhz3z-Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK\n",
        "*   punkt：这是一个预训练的分词器模型，用于将文本分割成句子和单词。这是许多NLP任务的基础步\n",
        "*  punkt_tab：这是另一个与punkt相关的分词器，可能用于处理特定格式的文本或提供额外的分词功能\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z17Hb6D20Ttq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Vrvbjj0XRA",
        "outputId": "aa5bd87a-ac89-4b12-cd90-3addb4d93bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   sent_tokenize: The sentence tokenizer takes care to split a text into sentences.\n",
        "*   word_tokenize: The word tokenizer takes care to split a text into words.\n",
        "\n",
        "*   拆解文本->向量化\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mU5MsslN02WV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk_sentences=sent_tokenize(par)\n",
        "nltk_words=word_tokenize(par)\n",
        "print(nltk_sentences,'\\n')\n",
        "print(nltk_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DON7Nik40_tR",
        "outputId": "c04529d5-c159-4eb0-a53f-a294d40e32a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['To Sherlock Holmes she is always the woman.', 'I have seldom heard himmention her under any other name.', 'In his eyes she eclipses andpredominates the whole of her sex.', 'It was not that he felt anyemotion akin to love for Irene Adler.', 'All emotions, and that oneparticularly, were abhorrent to his cold, precise but admirablybalanced mind.', 'He was, I take it, the most perfect reasoning andobserving machine that the world has seen, but as a lover he wouldhave placed himself in a false position.', 'He never spoke of the softerpassions, save with a gibe and a sneer.', \"They were admirable thingsfor the observer--excellent for drawing the veil from men's motivesand actions.\", 'But for the trained reasoner to admit such intrusionsinto his own delicate and finely adjusted temperament was tointroduce a distracting factor which might throw a doubt upon all hismental results.', 'Grit in a sensitive instrument, or a crack in one ofhis own high-power lenses, would not be more disturbing than a strongemotion in a nature such as his.', 'And yet there was but one woman tohim, and that woman was the late Irene Adler, of dubious andquestionable memory.'] \n",
            "\n",
            "['To', 'Sherlock', 'Holmes', 'she', 'is', 'always', 'the', 'woman', '.', 'I', 'have', 'seldom', 'heard', 'himmention', 'her', 'under', 'any', 'other', 'name', '.', 'In', 'his', 'eyes', 'she', 'eclipses', 'andpredominates', 'the', 'whole', 'of', 'her', 'sex', '.', 'It', 'was', 'not', 'that', 'he', 'felt', 'anyemotion', 'akin', 'to', 'love', 'for', 'Irene', 'Adler', '.', 'All', 'emotions', ',', 'and', 'that', 'oneparticularly', ',', 'were', 'abhorrent', 'to', 'his', 'cold', ',', 'precise', 'but', 'admirablybalanced', 'mind', '.', 'He', 'was', ',', 'I', 'take', 'it', ',', 'the', 'most', 'perfect', 'reasoning', 'andobserving', 'machine', 'that', 'the', 'world', 'has', 'seen', ',', 'but', 'as', 'a', 'lover', 'he', 'wouldhave', 'placed', 'himself', 'in', 'a', 'false', 'position', '.', 'He', 'never', 'spoke', 'of', 'the', 'softerpassions', ',', 'save', 'with', 'a', 'gibe', 'and', 'a', 'sneer', '.', 'They', 'were', 'admirable', 'thingsfor', 'the', 'observer', '--', 'excellent', 'for', 'drawing', 'the', 'veil', 'from', 'men', \"'s\", 'motivesand', 'actions', '.', 'But', 'for', 'the', 'trained', 'reasoner', 'to', 'admit', 'such', 'intrusionsinto', 'his', 'own', 'delicate', 'and', 'finely', 'adjusted', 'temperament', 'was', 'tointroduce', 'a', 'distracting', 'factor', 'which', 'might', 'throw', 'a', 'doubt', 'upon', 'all', 'hismental', 'results', '.', 'Grit', 'in', 'a', 'sensitive', 'instrument', ',', 'or', 'a', 'crack', 'in', 'one', 'ofhis', 'own', 'high-power', 'lenses', ',', 'would', 'not', 'be', 'more', 'disturbing', 'than', 'a', 'strongemotion', 'in', 'a', 'nature', 'such', 'as', 'his', '.', 'And', 'yet', 'there', 'was', 'but', 'one', 'woman', 'tohim', ',', 'and', 'that', 'woman', 'was', 'the', 'late', 'Irene', 'Adler', ',', 'of', 'dubious', 'andquestionable', 'memory', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy\n",
        "\n",
        "\n",
        "*   en_core_web_sm 包含处理en文本的所有组件与数据\n",
        "*   zh_core_web_sm 处理中文zh版本\n",
        "\n"
      ],
      "metadata": {
        "id": "PzkHgT8v1g83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "doc=nlp(par)"
      ],
      "metadata": {
        "id": "JOVPAM0z1kU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   spacy_sentences (doc.sents) : 文本拆解为句子 -> 向量化\n",
        "*   spacy_tokens (x for x in xxxx[i]) : 句子拆解为tokens -> 向量化\n",
        "\n"
      ],
      "metadata": {
        "id": "WvRPFIgL3HDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_sentences=list(doc.sents)\n",
        "spacy_tokens=[x for x in spacy_sentences[0]]\n",
        "print(spacy_sentences,'\\n')\n",
        "print(spacy_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9cLIpT63Gvs",
        "outputId": "65074e66-9657-4133-9516-0935da382a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[To Sherlock Holmes she is always the woman., I have seldom heard himmention her under any other name., In his eyes she eclipses andpredominates the whole of her sex., It was not that he felt anyemotion akin to love for Irene Adler., All emotions, and that oneparticularly, were abhorrent to his cold, precise but admirablybalanced mind., He was, I take it, the most perfect reasoning andobserving machine that the world has seen, but as a lover he wouldhave placed himself in a false position., He never spoke of the softerpassions, save with a gibe and a sneer., They were admirable thingsfor the observer--excellent for drawing the veil from men's motivesand actions., But for the trained reasoner to admit such intrusionsinto his own delicate and finely adjusted temperament was tointroduce a distracting factor which might throw a doubt upon all hismental results., Grit in a sensitive instrument, or a crack in one ofhis own high-power lenses, would not be more disturbing than a strongemotion in a nature such as his., And yet there was but one woman tohim, and that woman was the late Irene Adler, of dubious andquestionable memory.] \n",
            "\n",
            "[To, Sherlock, Holmes, she, is, always, the, woman, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sklearn Generalities （CountVectorizer&TfidfVectorizer）\n",
        "Classes likes `CountVectorizer` or `TfidfVectorizer` works in the following way:\n",
        "* Instantiate an object with specific parameters (`v = CountVectorizer(...)`)\n",
        "* Fit this object to your corpus = learn the vocabulary (method `v.fit(...)`)\n",
        "* Transform any piece of text you have into a vector (method `v.transform()`)\n",
        "*   **用CountVectorizer或者TfidfVectorizer做特征提取，文本转化为bow后才可以进行回归等操作**"
      ],
      "metadata": {
        "id": "SwO24rpG-Emv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
      ],
      "metadata": {
        "id": "UQ0R67V9_FDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "def 2 function for below analysis"
      ],
      "metadata": {
        "id": "8GqQOxch_Ig0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_vocabulary(vectorizer):\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "\n",
        "    print(f'Vocabulary size: {len(words)} words')\n",
        "\n",
        "    # we can print ~10 words per line\n",
        "    for l in np.array_split(words, math.ceil(len(words) / 10)):\n",
        "        print(''.join([f'{x:<15}' for x in l]))"
      ],
      "metadata": {
        "id": "h3uFIPBL-FDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxgmPDksgFP-"
      },
      "source": [
        "import os\n",
        "os.environ[\"FORCE_COLOR\"] = \"1\"\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "def show_bow(vectorizer, bow):\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # we can print ~8 words + coefs per line\n",
        "    for l in np.array_split(list(zip(words, bow)), math.ceil(len(words) / 8)):\n",
        "        print(' | '.join([colored(f'{w:<15}:{n:>2}', 'grey') if int(n) == 0 else colored(f'{w:<15}:{n:>2}', on_color='on_yellow', attrs=['bold']) for w, n in l ]))\n",
        "\n",
        "def show_bow_float(vectorizer, bow):\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # we can print ~6 words + coefs per line\n",
        "    for l in np.array_split(list(zip(words, bow)), math.ceil(len(words) / 6)):\n",
        "        print(' | '.join([colored(f'{w:<15}:{float(n):>0.2f}', 'grey') if float(n) == 0 else colored(f'{w:<15}:{float(n):>0.2f}', on_color='on_yellow', attrs=['bold']) for w, n in l ]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raw Count\n",
        "* We take a text, any text, and represent it as a vector\n",
        "* Each text is represented by a vector with **N** dimensions\n",
        "* Each dimension is representative of **1 word** of the vocabulary\n",
        "* The coefficient in dimension **k** is the number of times the word at index **k** in the vocabulary is seen in the represented text"
      ],
      "metadata": {
        "id": "x4SlAhQe-zI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eg: Reduced Vocabulary. (corpus: 1st paragraph of book, document:1 sentence)"
      ],
      "metadata": {
        "id": "_dJLJ7pZ_QFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_small= CountVectorizer(lowercase=True)\n",
        "count_small.fit(nltk_sentences)\n",
        "show_vocabulary(count_small)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSP6hgpq-67D",
        "outputId": "d5dd4e72-3221-4ffc-d1c0-c7f9b6a8ddae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 126 words\n",
            "abhorrent      actions        adjusted       adler          admirable      admirablybalancedadmit          akin           all            always         \n",
            "and            andobserving   andpredominatesandquestionableany            anyemotion     as             be             but            cold           \n",
            "crack          delicate       distracting    disturbing     doubt          drawing        dubious        eclipses       emotions       excellent      \n",
            "eyes           factor         false          felt           finely         for            from           gibe           grit           has            \n",
            "have           he             heard          her            high           himmention     himself        his            hismental      holmes         \n",
            "in             instrument     intrusionsinto irene          is             it             late           lenses         love           lover          \n",
            "machine        memory         men            might          mind           more           most           motivesand     name           nature         \n",
            "never          not            observer       of             ofhis          one            oneparticularlyor             other          own            \n",
            "perfect        placed         position       power          precise        reasoner       reasoning      results        save           seen           \n",
            "seldom         sensitive      sex            she            sherlock       sneer          softerpassions spoke          strongemotion  \n",
            "such           take           temperament    than           that           the            there          they           thingsfor      \n",
            "throw          to             tohim          tointroduce    trained        under          upon           veil           was            \n",
            "were           which          whole          with           woman          world          would          wouldhave      yet            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The option `lowercase` sets up one behavior of the raw count: do we consider `And` to be different than `and`?\n",
        "\n",
        "* `lowercase=False` gives 134 unique words in the vocabulary\n",
        "* `lowercase=True` gives 127 unique words"
      ],
      "metadata": {
        "id": "YXUpqJDQ_2rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = nltk_sentences[0]\n",
        "\n",
        "print(f'Text: \"{s}\"')\n",
        "bow = count_small.transform([s])\n",
        "print(f'BoW Shape: {bow.shape}')\n",
        "bow = bow.toarray()   # From sparse matrix to dense matrix (Careful with MEMORY)\n",
        "print(f'BoW Vector: {bow}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJT5BKEbAQi0",
        "outputId": "51ce3ba8-ebcf-40da-d2b0-8bceb764ccab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: \"To Sherlock Holmes she is always the woman.\"\n",
            "BoW Shape: (1, 126)\n",
            "BoW Vector: [[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_bow(count_small,bow[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOgjhpPSAEeV",
        "outputId": "a770c33f-908b-41d2-f369-4defb400b539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[30mabhorrent      : 0\u001b[0m | \u001b[30mactions        : 0\u001b[0m | \u001b[30madjusted       : 0\u001b[0m | \u001b[30madler          : 0\u001b[0m | \u001b[30madmirable      : 0\u001b[0m | \u001b[30madmirablybalanced: 0\u001b[0m | \u001b[30madmit          : 0\u001b[0m | \u001b[30makin           : 0\u001b[0m\n",
            "\u001b[30mall            : 0\u001b[0m | \u001b[1m\u001b[43malways         : 1\u001b[0m | \u001b[30mand            : 0\u001b[0m | \u001b[30mandobserving   : 0\u001b[0m | \u001b[30mandpredominates: 0\u001b[0m | \u001b[30mandquestionable: 0\u001b[0m | \u001b[30many            : 0\u001b[0m | \u001b[30manyemotion     : 0\u001b[0m\n",
            "\u001b[30mas             : 0\u001b[0m | \u001b[30mbe             : 0\u001b[0m | \u001b[30mbut            : 0\u001b[0m | \u001b[30mcold           : 0\u001b[0m | \u001b[30mcrack          : 0\u001b[0m | \u001b[30mdelicate       : 0\u001b[0m | \u001b[30mdistracting    : 0\u001b[0m | \u001b[30mdisturbing     : 0\u001b[0m\n",
            "\u001b[30mdoubt          : 0\u001b[0m | \u001b[30mdrawing        : 0\u001b[0m | \u001b[30mdubious        : 0\u001b[0m | \u001b[30meclipses       : 0\u001b[0m | \u001b[30memotions       : 0\u001b[0m | \u001b[30mexcellent      : 0\u001b[0m | \u001b[30meyes           : 0\u001b[0m | \u001b[30mfactor         : 0\u001b[0m\n",
            "\u001b[30mfalse          : 0\u001b[0m | \u001b[30mfelt           : 0\u001b[0m | \u001b[30mfinely         : 0\u001b[0m | \u001b[30mfor            : 0\u001b[0m | \u001b[30mfrom           : 0\u001b[0m | \u001b[30mgibe           : 0\u001b[0m | \u001b[30mgrit           : 0\u001b[0m | \u001b[30mhas            : 0\u001b[0m\n",
            "\u001b[30mhave           : 0\u001b[0m | \u001b[30mhe             : 0\u001b[0m | \u001b[30mheard          : 0\u001b[0m | \u001b[30mher            : 0\u001b[0m | \u001b[30mhigh           : 0\u001b[0m | \u001b[30mhimmention     : 0\u001b[0m | \u001b[30mhimself        : 0\u001b[0m | \u001b[30mhis            : 0\u001b[0m\n",
            "\u001b[30mhismental      : 0\u001b[0m | \u001b[1m\u001b[43mholmes         : 1\u001b[0m | \u001b[30min             : 0\u001b[0m | \u001b[30minstrument     : 0\u001b[0m | \u001b[30mintrusionsinto : 0\u001b[0m | \u001b[30mirene          : 0\u001b[0m | \u001b[1m\u001b[43mis             : 1\u001b[0m | \u001b[30mit             : 0\u001b[0m\n",
            "\u001b[30mlate           : 0\u001b[0m | \u001b[30mlenses         : 0\u001b[0m | \u001b[30mlove           : 0\u001b[0m | \u001b[30mlover          : 0\u001b[0m | \u001b[30mmachine        : 0\u001b[0m | \u001b[30mmemory         : 0\u001b[0m | \u001b[30mmen            : 0\u001b[0m | \u001b[30mmight          : 0\u001b[0m\n",
            "\u001b[30mmind           : 0\u001b[0m | \u001b[30mmore           : 0\u001b[0m | \u001b[30mmost           : 0\u001b[0m | \u001b[30mmotivesand     : 0\u001b[0m | \u001b[30mname           : 0\u001b[0m | \u001b[30mnature         : 0\u001b[0m | \u001b[30mnever          : 0\u001b[0m | \u001b[30mnot            : 0\u001b[0m\n",
            "\u001b[30mobserver       : 0\u001b[0m | \u001b[30mof             : 0\u001b[0m | \u001b[30mofhis          : 0\u001b[0m | \u001b[30mone            : 0\u001b[0m | \u001b[30moneparticularly: 0\u001b[0m | \u001b[30mor             : 0\u001b[0m | \u001b[30mother          : 0\u001b[0m | \u001b[30mown            : 0\u001b[0m\n",
            "\u001b[30mperfect        : 0\u001b[0m | \u001b[30mplaced         : 0\u001b[0m | \u001b[30mposition       : 0\u001b[0m | \u001b[30mpower          : 0\u001b[0m | \u001b[30mprecise        : 0\u001b[0m | \u001b[30mreasoner       : 0\u001b[0m | \u001b[30mreasoning      : 0\u001b[0m | \u001b[30mresults        : 0\u001b[0m\n",
            "\u001b[30msave           : 0\u001b[0m | \u001b[30mseen           : 0\u001b[0m | \u001b[30mseldom         : 0\u001b[0m | \u001b[30msensitive      : 0\u001b[0m | \u001b[30msex            : 0\u001b[0m | \u001b[1m\u001b[43mshe            : 1\u001b[0m | \u001b[1m\u001b[43msherlock       : 1\u001b[0m | \u001b[30msneer          : 0\u001b[0m\n",
            "\u001b[30msofterpassions : 0\u001b[0m | \u001b[30mspoke          : 0\u001b[0m | \u001b[30mstrongemotion  : 0\u001b[0m | \u001b[30msuch           : 0\u001b[0m | \u001b[30mtake           : 0\u001b[0m | \u001b[30mtemperament    : 0\u001b[0m | \u001b[30mthan           : 0\u001b[0m | \u001b[30mthat           : 0\u001b[0m\n",
            "\u001b[1m\u001b[43mthe            : 1\u001b[0m | \u001b[30mthere          : 0\u001b[0m | \u001b[30mthey           : 0\u001b[0m | \u001b[30mthingsfor      : 0\u001b[0m | \u001b[30mthrow          : 0\u001b[0m | \u001b[1m\u001b[43mto             : 1\u001b[0m | \u001b[30mtohim          : 0\u001b[0m | \u001b[30mtointroduce    : 0\u001b[0m\n",
            "\u001b[30mtrained        : 0\u001b[0m | \u001b[30munder          : 0\u001b[0m | \u001b[30mupon           : 0\u001b[0m | \u001b[30mveil           : 0\u001b[0m | \u001b[30mwas            : 0\u001b[0m | \u001b[30mwere           : 0\u001b[0m | \u001b[30mwhich          : 0\u001b[0m\n",
            "\u001b[30mwhole          : 0\u001b[0m | \u001b[30mwith           : 0\u001b[0m | \u001b[1m\u001b[43mwoman          : 1\u001b[0m | \u001b[30mworld          : 0\u001b[0m | \u001b[30mwould          : 0\u001b[0m | \u001b[30mwouldhave      : 0\u001b[0m | \u001b[30myet            : 0\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF\n",
        "The basic for TF-IDF is that cosine similarity with raw count coefficients puts too much emphasis on the number of occurences of a word within a document.\n",
        "\n",
        "Repeating a word will artifically increase the cosine similarity with any text containing this word.\n",
        "\n",
        "Consider which word would be important:\n",
        "1. One that is repeated a lot and equally present in each document\n",
        "1. One that appears a lot only in a few document\n",
        "TF-IDF computes coefficients:\n",
        "* Low values for common words (ie present in the document, but quite common over the corpus)\n",
        "* High values for uncommon words (ie present in the document, but not common over the corpus)\n",
        "\n",
        "We consider one specific document, and one specific word.\n",
        "\n",
        "* **TF = Term Frequency**: the number of times the word appears in the document\n",
        "* **DF = Document Frequency**: the number of document in the corpus, in which the word appears\n",
        "* **IDF = Inverse Document Frequency**: the inverse of the Document Frequency.\n",
        "\n",
        "Logarithms are introduced, to reflect that 100 times a word does not deliver 100 times the information.\n",
        "\n",
        "Given a word **w**, a document **d** in a corpus of **D** documents:\n",
        "\n",
        "$\\textrm{TF-IDF(w, d) = TF(w, d) * IDF(w)}$\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "\\textrm{IDF(w) = log} \\left( \\frac{1 + \\textrm{D}}{1 + \\textrm{DF(w)}} \\right) + 1\n",
        "\\end{align}\n",
        "$"
      ],
      "metadata": {
        "id": "oYwXys07AaSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf=TfidfVectorizer()\n",
        "tfidf.fit(nltk_sentences)\n",
        "show_vocabulary(tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0R2-1O5A9Ay",
        "outputId": "2d21cca1-5b21-47d1-e7d9-c89301a3eab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 126 words\n",
            "abhorrent      actions        adjusted       adler          admirable      admirablybalancedadmit          akin           all            always         \n",
            "and            andobserving   andpredominatesandquestionableany            anyemotion     as             be             but            cold           \n",
            "crack          delicate       distracting    disturbing     doubt          drawing        dubious        eclipses       emotions       excellent      \n",
            "eyes           factor         false          felt           finely         for            from           gibe           grit           has            \n",
            "have           he             heard          her            high           himmention     himself        his            hismental      holmes         \n",
            "in             instrument     intrusionsinto irene          is             it             late           lenses         love           lover          \n",
            "machine        memory         men            might          mind           more           most           motivesand     name           nature         \n",
            "never          not            observer       of             ofhis          one            oneparticularlyor             other          own            \n",
            "perfect        placed         position       power          precise        reasoner       reasoning      results        save           seen           \n",
            "seldom         sensitive      sex            she            sherlock       sneer          softerpassions spoke          strongemotion  \n",
            "such           take           temperament    than           that           the            there          they           thingsfor      \n",
            "throw          to             tohim          tointroduce    trained        under          upon           veil           was            \n",
            "were           which          whole          with           woman          world          would          wouldhave      yet            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = nltk_sentences[0]\n",
        "\n",
        "print(f'Text: \"{s}\"')\n",
        "bow = tfidf.transform([s])\n",
        "print(f'BoW Shape: {bow.shape}')\n",
        "bow = bow.toarray()   # From sparse matrix to dense matrix (Careful with MEMORY)\n",
        "print(f'BoW Vector: {bow}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKJ5A7RDBffU",
        "outputId": "c4aae5d8-e080-47e4-cfc2-22d8303951aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: \"To Sherlock Holmes she is always the woman.\"\n",
            "BoW Shape: (1, 126)\n",
            "BoW Vector: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40271589 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.40271589 0.         0.         0.         0.\n",
            "  0.40271589 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.34422688 0.40271589 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.20274065 0.         0.         0.\n",
            "  0.         0.27053945 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.34422688 0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_bow_float(tfidf,bow[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZs-oHI9BJwc",
        "outputId": "8e324cbb-7086-435c-bcd7-cc91eb660c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[30mabhorrent      :0.00\u001b[0m | \u001b[30mactions        :0.00\u001b[0m | \u001b[30madjusted       :0.00\u001b[0m | \u001b[30madler          :0.00\u001b[0m | \u001b[30madmirable      :0.00\u001b[0m | \u001b[30madmirablybalanced:0.00\u001b[0m\n",
            "\u001b[30madmit          :0.00\u001b[0m | \u001b[30makin           :0.00\u001b[0m | \u001b[30mall            :0.00\u001b[0m | \u001b[1m\u001b[43malways         :0.40\u001b[0m | \u001b[30mand            :0.00\u001b[0m | \u001b[30mandobserving   :0.00\u001b[0m\n",
            "\u001b[30mandpredominates:0.00\u001b[0m | \u001b[30mandquestionable:0.00\u001b[0m | \u001b[30many            :0.00\u001b[0m | \u001b[30manyemotion     :0.00\u001b[0m | \u001b[30mas             :0.00\u001b[0m | \u001b[30mbe             :0.00\u001b[0m\n",
            "\u001b[30mbut            :0.00\u001b[0m | \u001b[30mcold           :0.00\u001b[0m | \u001b[30mcrack          :0.00\u001b[0m | \u001b[30mdelicate       :0.00\u001b[0m | \u001b[30mdistracting    :0.00\u001b[0m | \u001b[30mdisturbing     :0.00\u001b[0m\n",
            "\u001b[30mdoubt          :0.00\u001b[0m | \u001b[30mdrawing        :0.00\u001b[0m | \u001b[30mdubious        :0.00\u001b[0m | \u001b[30meclipses       :0.00\u001b[0m | \u001b[30memotions       :0.00\u001b[0m | \u001b[30mexcellent      :0.00\u001b[0m\n",
            "\u001b[30meyes           :0.00\u001b[0m | \u001b[30mfactor         :0.00\u001b[0m | \u001b[30mfalse          :0.00\u001b[0m | \u001b[30mfelt           :0.00\u001b[0m | \u001b[30mfinely         :0.00\u001b[0m | \u001b[30mfor            :0.00\u001b[0m\n",
            "\u001b[30mfrom           :0.00\u001b[0m | \u001b[30mgibe           :0.00\u001b[0m | \u001b[30mgrit           :0.00\u001b[0m | \u001b[30mhas            :0.00\u001b[0m | \u001b[30mhave           :0.00\u001b[0m | \u001b[30mhe             :0.00\u001b[0m\n",
            "\u001b[30mheard          :0.00\u001b[0m | \u001b[30mher            :0.00\u001b[0m | \u001b[30mhigh           :0.00\u001b[0m | \u001b[30mhimmention     :0.00\u001b[0m | \u001b[30mhimself        :0.00\u001b[0m | \u001b[30mhis            :0.00\u001b[0m\n",
            "\u001b[30mhismental      :0.00\u001b[0m | \u001b[1m\u001b[43mholmes         :0.40\u001b[0m | \u001b[30min             :0.00\u001b[0m | \u001b[30minstrument     :0.00\u001b[0m | \u001b[30mintrusionsinto :0.00\u001b[0m | \u001b[30mirene          :0.00\u001b[0m\n",
            "\u001b[1m\u001b[43mis             :0.40\u001b[0m | \u001b[30mit             :0.00\u001b[0m | \u001b[30mlate           :0.00\u001b[0m | \u001b[30mlenses         :0.00\u001b[0m | \u001b[30mlove           :0.00\u001b[0m | \u001b[30mlover          :0.00\u001b[0m\n",
            "\u001b[30mmachine        :0.00\u001b[0m | \u001b[30mmemory         :0.00\u001b[0m | \u001b[30mmen            :0.00\u001b[0m | \u001b[30mmight          :0.00\u001b[0m | \u001b[30mmind           :0.00\u001b[0m | \u001b[30mmore           :0.00\u001b[0m\n",
            "\u001b[30mmost           :0.00\u001b[0m | \u001b[30mmotivesand     :0.00\u001b[0m | \u001b[30mname           :0.00\u001b[0m | \u001b[30mnature         :0.00\u001b[0m | \u001b[30mnever          :0.00\u001b[0m | \u001b[30mnot            :0.00\u001b[0m\n",
            "\u001b[30mobserver       :0.00\u001b[0m | \u001b[30mof             :0.00\u001b[0m | \u001b[30mofhis          :0.00\u001b[0m | \u001b[30mone            :0.00\u001b[0m | \u001b[30moneparticularly:0.00\u001b[0m | \u001b[30mor             :0.00\u001b[0m\n",
            "\u001b[30mother          :0.00\u001b[0m | \u001b[30mown            :0.00\u001b[0m | \u001b[30mperfect        :0.00\u001b[0m | \u001b[30mplaced         :0.00\u001b[0m | \u001b[30mposition       :0.00\u001b[0m | \u001b[30mpower          :0.00\u001b[0m\n",
            "\u001b[30mprecise        :0.00\u001b[0m | \u001b[30mreasoner       :0.00\u001b[0m | \u001b[30mreasoning      :0.00\u001b[0m | \u001b[30mresults        :0.00\u001b[0m | \u001b[30msave           :0.00\u001b[0m | \u001b[30mseen           :0.00\u001b[0m\n",
            "\u001b[30mseldom         :0.00\u001b[0m | \u001b[30msensitive      :0.00\u001b[0m | \u001b[30msex            :0.00\u001b[0m | \u001b[1m\u001b[43mshe            :0.34\u001b[0m | \u001b[1m\u001b[43msherlock       :0.40\u001b[0m | \u001b[30msneer          :0.00\u001b[0m\n",
            "\u001b[30msofterpassions :0.00\u001b[0m | \u001b[30mspoke          :0.00\u001b[0m | \u001b[30mstrongemotion  :0.00\u001b[0m | \u001b[30msuch           :0.00\u001b[0m | \u001b[30mtake           :0.00\u001b[0m | \u001b[30mtemperament    :0.00\u001b[0m\n",
            "\u001b[30mthan           :0.00\u001b[0m | \u001b[30mthat           :0.00\u001b[0m | \u001b[1m\u001b[43mthe            :0.20\u001b[0m | \u001b[30mthere          :0.00\u001b[0m | \u001b[30mthey           :0.00\u001b[0m | \u001b[30mthingsfor      :0.00\u001b[0m\n",
            "\u001b[30mthrow          :0.00\u001b[0m | \u001b[1m\u001b[43mto             :0.27\u001b[0m | \u001b[30mtohim          :0.00\u001b[0m | \u001b[30mtointroduce    :0.00\u001b[0m | \u001b[30mtrained        :0.00\u001b[0m | \u001b[30munder          :0.00\u001b[0m\n",
            "\u001b[30mupon           :0.00\u001b[0m | \u001b[30mveil           :0.00\u001b[0m | \u001b[30mwas            :0.00\u001b[0m | \u001b[30mwere           :0.00\u001b[0m | \u001b[30mwhich          :0.00\u001b[0m | \u001b[30mwhole          :0.00\u001b[0m\n",
            "\u001b[30mwith           :0.00\u001b[0m | \u001b[1m\u001b[43mwoman          :0.34\u001b[0m | \u001b[30mworld          :0.00\u001b[0m | \u001b[30mwould          :0.00\u001b[0m | \u001b[30mwouldhave      :0.00\u001b[0m | \u001b[30myet            :0.00\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the IDF of some words.\n",
        "\n",
        "* High IDF = word that appears in few documents\n",
        "* Low IDF = word that appears in most of documents"
      ],
      "metadata": {
        "id": "3Q4sLbKUCLBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = tfidf.get_feature_names_out()\n",
        "word = input('Word: ').lower()\n",
        "\n",
        "if word in words:\n",
        "    k = list(words).index(word)\n",
        "    print(f'IDF({words[k]}) = {tfidf.idf_[k]}')\n",
        "else:\n",
        "    print('Not in vocabulary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5pF6HjdCLwc",
        "outputId": "98ca0d59-e2cd-4b00-f116-e77191b8a56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: sherlock\n",
            "IDF(sherlock) = 2.791759469228055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More than one TF_IDF:\n",
        "\n",
        "There is a family of TF-IDF formulas.\n",
        "\n",
        "Another example is the **sublinear TF**, which is then:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "\\textrm{TF(w, d) = 1 + log} \\left( raw count \\right)\n",
        "\\end{align}\n",
        "$"
      ],
      "metadata": {
        "id": "IElNGl_BChNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_sublinear = TfidfVectorizer(sublinear_tf=True)\n",
        "tfidf_sublinear.fit(nltk_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "CQsJ6bjECokG",
        "outputId": "f6ad97f2-9d65-4a8d-c9cd-41e5bce93bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(sublinear_tf=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(sublinear_tf=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(sublinear_tf=True)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = nltk_sentences[0]\n",
        "\n",
        "print(f'Text: \"{s}\"')\n",
        "bow_sl = tfidf_sublinear.transform([s])\n",
        "print(f'BoW Shape: {bow_sl.shape}')\n",
        "bow_sl = bow_sl.toarray()   # From sparse matrix to dense matrix (Careful with MEMORY)\n",
        "print(f'BoW Vector: {bow_sl}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeoHK32XCr08",
        "outputId": "49b5084b-8b64-4bd9-b08b-d03f8c71c841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: \"To Sherlock Holmes she is always the woman.\"\n",
            "BoW Shape: (1, 126)\n",
            "BoW Vector: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40271589 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.40271589 0.         0.         0.         0.\n",
            "  0.40271589 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.34422688 0.40271589 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.20274065 0.         0.         0.\n",
            "  0.         0.27053945 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.34422688 0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_bow_float(tfidf_sublinear, bow_sl[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-tTecw-C2tC",
        "outputId": "932e67b2-38f2-4cc5-b1dc-db7869d5abc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[30mabhorrent      :0.00\u001b[0m | \u001b[30mactions        :0.00\u001b[0m | \u001b[30madjusted       :0.00\u001b[0m | \u001b[30madler          :0.00\u001b[0m | \u001b[30madmirable      :0.00\u001b[0m | \u001b[30madmirablybalanced:0.00\u001b[0m\n",
            "\u001b[30madmit          :0.00\u001b[0m | \u001b[30makin           :0.00\u001b[0m | \u001b[30mall            :0.00\u001b[0m | \u001b[1m\u001b[43malways         :0.40\u001b[0m | \u001b[30mand            :0.00\u001b[0m | \u001b[30mandobserving   :0.00\u001b[0m\n",
            "\u001b[30mandpredominates:0.00\u001b[0m | \u001b[30mandquestionable:0.00\u001b[0m | \u001b[30many            :0.00\u001b[0m | \u001b[30manyemotion     :0.00\u001b[0m | \u001b[30mas             :0.00\u001b[0m | \u001b[30mbe             :0.00\u001b[0m\n",
            "\u001b[30mbut            :0.00\u001b[0m | \u001b[30mcold           :0.00\u001b[0m | \u001b[30mcrack          :0.00\u001b[0m | \u001b[30mdelicate       :0.00\u001b[0m | \u001b[30mdistracting    :0.00\u001b[0m | \u001b[30mdisturbing     :0.00\u001b[0m\n",
            "\u001b[30mdoubt          :0.00\u001b[0m | \u001b[30mdrawing        :0.00\u001b[0m | \u001b[30mdubious        :0.00\u001b[0m | \u001b[30meclipses       :0.00\u001b[0m | \u001b[30memotions       :0.00\u001b[0m | \u001b[30mexcellent      :0.00\u001b[0m\n",
            "\u001b[30meyes           :0.00\u001b[0m | \u001b[30mfactor         :0.00\u001b[0m | \u001b[30mfalse          :0.00\u001b[0m | \u001b[30mfelt           :0.00\u001b[0m | \u001b[30mfinely         :0.00\u001b[0m | \u001b[30mfor            :0.00\u001b[0m\n",
            "\u001b[30mfrom           :0.00\u001b[0m | \u001b[30mgibe           :0.00\u001b[0m | \u001b[30mgrit           :0.00\u001b[0m | \u001b[30mhas            :0.00\u001b[0m | \u001b[30mhave           :0.00\u001b[0m | \u001b[30mhe             :0.00\u001b[0m\n",
            "\u001b[30mheard          :0.00\u001b[0m | \u001b[30mher            :0.00\u001b[0m | \u001b[30mhigh           :0.00\u001b[0m | \u001b[30mhimmention     :0.00\u001b[0m | \u001b[30mhimself        :0.00\u001b[0m | \u001b[30mhis            :0.00\u001b[0m\n",
            "\u001b[30mhismental      :0.00\u001b[0m | \u001b[1m\u001b[43mholmes         :0.40\u001b[0m | \u001b[30min             :0.00\u001b[0m | \u001b[30minstrument     :0.00\u001b[0m | \u001b[30mintrusionsinto :0.00\u001b[0m | \u001b[30mirene          :0.00\u001b[0m\n",
            "\u001b[1m\u001b[43mis             :0.40\u001b[0m | \u001b[30mit             :0.00\u001b[0m | \u001b[30mlate           :0.00\u001b[0m | \u001b[30mlenses         :0.00\u001b[0m | \u001b[30mlove           :0.00\u001b[0m | \u001b[30mlover          :0.00\u001b[0m\n",
            "\u001b[30mmachine        :0.00\u001b[0m | \u001b[30mmemory         :0.00\u001b[0m | \u001b[30mmen            :0.00\u001b[0m | \u001b[30mmight          :0.00\u001b[0m | \u001b[30mmind           :0.00\u001b[0m | \u001b[30mmore           :0.00\u001b[0m\n",
            "\u001b[30mmost           :0.00\u001b[0m | \u001b[30mmotivesand     :0.00\u001b[0m | \u001b[30mname           :0.00\u001b[0m | \u001b[30mnature         :0.00\u001b[0m | \u001b[30mnever          :0.00\u001b[0m | \u001b[30mnot            :0.00\u001b[0m\n",
            "\u001b[30mobserver       :0.00\u001b[0m | \u001b[30mof             :0.00\u001b[0m | \u001b[30mofhis          :0.00\u001b[0m | \u001b[30mone            :0.00\u001b[0m | \u001b[30moneparticularly:0.00\u001b[0m | \u001b[30mor             :0.00\u001b[0m\n",
            "\u001b[30mother          :0.00\u001b[0m | \u001b[30mown            :0.00\u001b[0m | \u001b[30mperfect        :0.00\u001b[0m | \u001b[30mplaced         :0.00\u001b[0m | \u001b[30mposition       :0.00\u001b[0m | \u001b[30mpower          :0.00\u001b[0m\n",
            "\u001b[30mprecise        :0.00\u001b[0m | \u001b[30mreasoner       :0.00\u001b[0m | \u001b[30mreasoning      :0.00\u001b[0m | \u001b[30mresults        :0.00\u001b[0m | \u001b[30msave           :0.00\u001b[0m | \u001b[30mseen           :0.00\u001b[0m\n",
            "\u001b[30mseldom         :0.00\u001b[0m | \u001b[30msensitive      :0.00\u001b[0m | \u001b[30msex            :0.00\u001b[0m | \u001b[1m\u001b[43mshe            :0.34\u001b[0m | \u001b[1m\u001b[43msherlock       :0.40\u001b[0m | \u001b[30msneer          :0.00\u001b[0m\n",
            "\u001b[30msofterpassions :0.00\u001b[0m | \u001b[30mspoke          :0.00\u001b[0m | \u001b[30mstrongemotion  :0.00\u001b[0m | \u001b[30msuch           :0.00\u001b[0m | \u001b[30mtake           :0.00\u001b[0m | \u001b[30mtemperament    :0.00\u001b[0m\n",
            "\u001b[30mthan           :0.00\u001b[0m | \u001b[30mthat           :0.00\u001b[0m | \u001b[1m\u001b[43mthe            :0.20\u001b[0m | \u001b[30mthere          :0.00\u001b[0m | \u001b[30mthey           :0.00\u001b[0m | \u001b[30mthingsfor      :0.00\u001b[0m\n",
            "\u001b[30mthrow          :0.00\u001b[0m | \u001b[1m\u001b[43mto             :0.27\u001b[0m | \u001b[30mtohim          :0.00\u001b[0m | \u001b[30mtointroduce    :0.00\u001b[0m | \u001b[30mtrained        :0.00\u001b[0m | \u001b[30munder          :0.00\u001b[0m\n",
            "\u001b[30mupon           :0.00\u001b[0m | \u001b[30mveil           :0.00\u001b[0m | \u001b[30mwas            :0.00\u001b[0m | \u001b[30mwere           :0.00\u001b[0m | \u001b[30mwhich          :0.00\u001b[0m | \u001b[30mwhole          :0.00\u001b[0m\n",
            "\u001b[30mwith           :0.00\u001b[0m | \u001b[1m\u001b[43mwoman          :0.34\u001b[0m | \u001b[30mworld          :0.00\u001b[0m | \u001b[30mwould          :0.00\u001b[0m | \u001b[30mwouldhave      :0.00\u001b[0m | \u001b[30myet            :0.00\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'yet'\n",
        "\n",
        "index = words.tolist().index(word)\n",
        "\n",
        "bow = tfidf.transform([s]).toarray()\n",
        "\n",
        "print(f'Word: \"{word}\"')\n",
        "print(f'TF-IDF with Natural TF   = {bow[0][index]:0.4f}')\n",
        "print(f'TF-IDF with Sublinear TF = {bow_sl[0][index]:0.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4ec0CqEC6BE",
        "outputId": "45901e69-83d9-407e-fed6-6ed1b107465f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: \"yet\"\n",
            "TF-IDF with Natural TF   = 0.0000\n",
            "TF-IDF with Sublinear TF = 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'yet'\n",
        "s = nltk_sentences[0]\n",
        "s = s + ' '.join(100 * [word])\n",
        "\n",
        "bow = tfidf.transform([s]).toarray()\n",
        "bow_sl = tfidf_sublinear.transform([s]).toarray()\n",
        "\n",
        "index = words.tolist().index(word)\n",
        "print(f'Word: \"{word}\"')\n",
        "print(f'TF-IDF with Natural TF   = {bow[0][index]:0.4f}')\n",
        "print(f'TF-IDF with Sublinear TF = {bow_sl[0][index]:0.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e5OAprLC-lR",
        "outputId": "5e8f335b-f48b-4536-e6d6-cfe8af04d2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: \"yet\"\n",
            "TF-IDF with Natural TF   = 0.9997\n",
            "TF-IDF with Sublinear TF = 0.9143\n"
          ]
        }
      ]
    }
  ]
}