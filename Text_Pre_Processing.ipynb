{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jiaye39/TimeSeriesAnalysis/blob/main/Text_Pre_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLjCYKgdUjVo"
      },
      "source": [
        "# Text Pre-Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83SsP2zLU89r"
      },
      "source": [
        "The texts we have access to will be noisy:\n",
        "* Lots of unique words, including numbers and identifiers\n",
        "* Typos\n",
        "* Many declinations of the same word (plural, conjugation, ...)\n",
        "\n",
        "The pre-processing is how we modify the text BEFORE turning it into BoW vectors, and it has 2 main targets:\n",
        "* Retain information in vectors (similarity in text equals similarity in cosine)\n",
        "* Separate noise from information (remove unnecessary coefficients)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIccoqr-Vuy6"
      },
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRCYWOP1RS5K"
      },
      "source": [
        "## SKLEARN Generalities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE4wvrdYRWnX"
      },
      "source": [
        "The classes `CountVectorizer` and `TfidfVectorizer` have the same interface and the same arguments for their `__init__` method.\n",
        "\n",
        "What is explained for one class is valid for the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNuZNnD-elyo"
      },
      "source": [
        "def show_vocabulary(vectorizer, word_size=15, words_per_line=10):\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "\n",
        "    print(f'Vocabulary size: {len(words)} words')\n",
        "\n",
        "    word_format = f'<{word_size}'\n",
        "    for l in np.array_split(words, math.ceil(len(words) / words_per_line)):\n",
        "        print(''.join([f'{x:{word_format}}' for x in l]))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxgmPDksgFP-"
      },
      "source": [
        "import os\n",
        "os.environ[\"FORCE_COLOR\"] = \"1\"\n",
        "\n",
        "from termcolor import colored\n",
        "\n",
        "def show_bow(vectorizer, bow, word_size=15, words_per_line=8):\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "\n",
        "    word_format = f'<{word_size}'\n",
        "    for l in np.array_split(list(zip(words, bow)), math.ceil(len(words) / words_per_line)):\n",
        "        print(' | '.join([colored(f'{w:{word_format}}:{n:>2}', 'grey') if int(n) == 0 else colored(f'{w:{word_format}}:{n:>2}', on_color='on_yellow', attrs=['bold']) for w, n in l ]))\n",
        "\n",
        "def show_bow_float(vectorizer, bow, word_size=15, words_per_line=6):\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "\n",
        "    word_format = f'<{word_size}'\n",
        "    for l in np.array_split(list(zip(words, bow)), math.ceil(len(words) / words_per_line)):\n",
        "        print(' | '.join([colored(f'{w:word_format}:{float(n):>0.2f}', 'grey') if float(n) == 0 else colored(f'{w:word_format}:{float(n):>0.2f}', on_color='on_yellow', attrs=['bold']) for w, n in l ]))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHyfUpJJmdbl"
      },
      "source": [
        "## Real-Life Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1a6hshWoC_H"
      },
      "source": [
        "Books are very clean texts. Real-Life corpuses including user-generated material will be on the opposite of the spectrum, and will include typos, strange usernames, artefacts of all kinds...\n",
        "\n",
        "The \"20 newsgroups\" dataset is a classical NLP dataset. Newsgroups are the ancestors of reddit, people could post messages and reply in a thread.\n",
        "\n",
        "* **Corpus**: newsgroup messages\n",
        "* **Document**: full text of 1 message"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV7JF84EmmLO"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5a-35WInID6"
      },
      "source": [
        "newsgroups = fetch_20newsgroups()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Me_M00nQC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d7de2c-666e-4e12-8cfe-68e770f47790"
      },
      "source": [
        "print(f'Number of documents: {len(newsgroups.data)}')\n",
        "print()\n",
        "print(f'Sample document:\\n\\n{\"*\" * 80}\\n{newsgroups.data[12]}\\n{\"*\" * 80}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 11314\n",
            "\n",
            "Sample document:\n",
            "\n",
            "********************************************************************************\n",
            "From: rodc@fc.hp.com (Rod Cerkoney)\n",
            "Subject: *$G4qxF,fekVH6\n",
            "Nntp-Posting-Host: hpfcmrc.fc.hp.com\n",
            "Organization: Hewlett Packard, Fort Collins, CO\n",
            "X-Newsreader: TIN [version 1.1 PL8.5]\n",
            "Lines: 15\n",
            "\n",
            "\n",
            "\n",
            "--\n",
            "\n",
            "\n",
            "Regards,\n",
            "Rod Cerkoney\n",
            "                                                        /\\\n",
            "______________________________________________         /~~\\\n",
            "                                                      /    \\\n",
            "  Rod Cerkoney MS 37     email:                      /      \\ \n",
            "  Hewlett Packard         rodc@fc.hp.com        /\\  /        \\  \n",
            "  3404 East Harmony Rd.  Hpdesk:               /  \\/          \\    /\\\n",
            "  Fort Collins, CO 80525  HP4000/UX           /    \\           \\  /  \\\n",
            "_____________________________________________/      \\           \\/    \\__\n",
            "\n",
            "********************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMeO45zLpJQm"
      },
      "source": [
        "Here is the problem:\n",
        "* Vocabulary is much larger (130107 unique words)\n",
        "* Lots of \"garbage\" in vocabulary (\"mbocjlo3\", \"mc2i\", \"mc68882rc25\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XntkO1a8UukG"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrBhPPaaneBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d683fc-3877-45f8-e279-7447d704b412"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count = CountVectorizer()\n",
        "count.fit(newsgroups.data)\n",
        "words = count.get_feature_names_out()\n",
        "print(f'Vocabulary size: {len(words)} words')\n",
        "print('First 20 vocabulary words:')\n",
        "\n",
        "word_size = 15 # Using default word_size from show_vocabulary\n",
        "line_words = words[:20]\n",
        "print(''.join([f'{x:<{word_size}}' for x in line_words]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 130107 words\n",
            "First 20 vocabulary words:\n",
            "00             000            0000           00000          000000         00000000       0000000004     0000000005     00000000b      00000001       00000001b      0000000667     00000010       00000010b      00000011       00000011b      0000001200     00000074       00000093       000000e5       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mpMBuLxWSzq"
      },
      "source": [
        "# Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffwqr2k-WV61"
      },
      "source": [
        "**Curse of Dimensionality**\n",
        "\n",
        "Downstream applications (the applications that will use the vectors) are sensitive to the number of dimensions of feature vectors.\n",
        "\n",
        "* Logistic Regression: with d the number of dimensions of vectors, and n the number of samples:\n",
        "   * CPU complexity of `fit()` is $\\textrm{O(nd)}$\n",
        "   * RAM complexity of `fit()` is $\\textrm{O(nd + n + d)}$\n",
        "\n",
        "This is solved by removing words from the vocabulary (**stopping**, filtering, customized tokenization, ...)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Vocabulary Gap**\n",
        "\n",
        "* Verb conjugation will result in different unique words, that appear as separated dimensions.\n",
        "* Plurals will also generate unique words.\n",
        "\n",
        "For example 'make', 'makes', 'made' are individual words. As well as 'horse' and 'horses'.\n",
        "\n",
        "Consider two texts, does it make them dissimilar if one uses 'horse' and the other uses 'horses'?\n",
        "\n",
        "This is solved by reducing words to a 'basic' version (**stemming**, **lemmatizing**)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8etrE8wa7u6"
      },
      "source": [
        "# Stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF9SJB4Oa9z4"
      },
      "source": [
        "This is the process of removing **stopwords** from the text.\n",
        "\n",
        "Stopwords are words that are needed to make a sentence, but do not bring any information to the reader.\n",
        "\n",
        "Consider english words such as 'the', 'a', 'that'.\n",
        "\n",
        "* Each language has a list of stopwords.\n",
        "* Based on your corpus, there might be additional stopwords to consider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxK_axQebp1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2abb415-3cdb-4816-acb6-c9bf5d9c83a3"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktugr6XkWVFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aab3ca4-dd10-4e18-bcb6-05dddcb683b9"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = stopwords.words('english')\n",
        "print(f'Number of stopwords: {len(stops)}')\n",
        "\n",
        "for l in np.array_split(stops, 15):\n",
        "    print(' '.join([f'{w:<12}' for w in l]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of stopwords: 198\n",
            "a            about        above        after        again        against      ain          all          am           an           and          any          are          aren        \n",
            "aren't       as           at           be           because      been         before       being        below        between      both         but          by           can         \n",
            "couldn       couldn't     d            did          didn         didn't       do           does         doesn        doesn't      doing        don          don't        down        \n",
            "during       each         few          for          from         further      had          hadn         hadn't       has          hasn         hasn't       have        \n",
            "haven        haven't      having       he           he'd         he'll        her          here         hers         herself      he's         him          himself     \n",
            "his          how          i            i'd          if           i'll         i'm          in           into         is           isn          isn't        it          \n",
            "it'd         it'll        it's         its          itself       i've         just         ll           m            ma           me           mightn       mightn't    \n",
            "more         most         mustn        mustn't      my           myself       needn        needn't      no           nor          not          now          o           \n",
            "of           off          on           once         only         or           other        our          ours         ourselves    out          over         own         \n",
            "re           s            same         shan         shan't       she          she'd        she'll       she's        should       shouldn      shouldn't    should've   \n",
            "so           some         such         t            than         that         that'll      the          their        theirs       them         themselves   then        \n",
            "there        these        they         they'd       they'll      they're      they've      this         those        through      to           too          under       \n",
            "until        up           ve           very         was          wasn         wasn't       we           we'd         we'll        we're        were         weren       \n",
            "weren't      we've        what         when         where        which        while        who          whom         why          will         with         won         \n",
            "won't        wouldn       wouldn't     y            you          you'd        you'll       your         you're       yours        yourself     yourselves   you've      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_pkfHYfcQ4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f65ba97-6d85-4bd8-d1d8-8f2070d69e71"
      },
      "source": [
        "count = CountVectorizer(stop_words=stops)\n",
        "count.fit(newsgroups.data)\n",
        "\n",
        "vocab_stopped = count.get_feature_names_out()\n",
        "print(f'Size of vocabulary: {len(vocab_stopped)}')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 129963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb8-c1vpgwww"
      },
      "source": [
        "# Filter by Token Pattern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ToRWPHcgzPU"
      },
      "source": [
        "Accept only words that correspond to a regular expression pattern.\n",
        "\n",
        "See [Link](https://docs.python.org/3/howto/regex.html) about Regular Expressions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smG7dWnDfsX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2dfb0a-264b-4cfd-be43-6afadd09504c"
      },
      "source": [
        "count = CountVectorizer(\n",
        "    stop_words=stops,\n",
        "    token_pattern=r'\\b[a-z]+\\b',   # This pattern is positive for a word that contains only letters\n",
        ")\n",
        "count.fit(newsgroups.data)\n",
        "\n",
        "vocab_pattern = count.get_feature_names_out()\n",
        "print(f'Size of vocabulary: {len(vocab_pattern)}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 81622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMHK57Hqgbob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50edf055-40ba-4c1f-fc36-a759c73fb1a1"
      },
      "source": [
        "print(' '.join([f'{w:<10}' for w in vocab_stopped[:10]]))\n",
        "print(' '.join([f'{w:<10}' for w in vocab_pattern[:10]]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00         000        0000       00000      000000     00000000   0000000004 0000000005 00000000b  00000001  \n",
            "aa         aaa        aaaa       aaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg aaaaagggghhhh aaaarrgghhhh aaah       aaahh      aaahhhh   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFvu8Gjoc7Qz"
      },
      "source": [
        "# Filtering by Frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHozTFrzdE-R"
      },
      "source": [
        "Retain only the top N tokens, based on the number of times they appear in the complete corpus.\n",
        "\n",
        "Use the `max_features` argument of the vectorizer.\n",
        "\n",
        "Typical usage:\n",
        "* `max_features=50000`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNNTK9gBcywh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1f4db6-572e-41dd-d5c2-42061e08623c"
      },
      "source": [
        "count = CountVectorizer(\n",
        "    stop_words=stops,\n",
        "    token_pattern=r'[a-z]+',\n",
        "    max_features=50000\n",
        ")\n",
        "count.fit(newsgroups.data)\n",
        "\n",
        "vocab_top = count.get_feature_names_out()\n",
        "print(f'Size of vocabulary: {len(vocab_top)}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxGjvD2ifPVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c122796-fc24-4284-a168-ade343229bc6"
      },
      "source": [
        "print(' '.join([f'{w:<10}' for w in vocab_stopped[:10]]))\n",
        "print(' '.join([f'{w:<10}' for w in vocab_top[:10]]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00         000        0000       00000      000000     00000000   0000000004 0000000005 00000000b  00000001  \n",
            "aa         aaa        aaaarrgghhhh aaah       aaahhhh    aaai       aab        aachen     aad        aaf       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "vocab_top[::2000]"
      ],
      "metadata": {
        "id": "mbvugovO1HYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba2b4f4-a77e-40e0-abb6-b07710d24954"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['aa', 'apeldoornseweg', 'beeblbrox', 'bvsd', 'clutch',\n",
              "       'crystallography', 'dingebre', 'elicit', 'flags', 'gunning',\n",
              "       'icons', 'jackw', 'kotdohl', 'lutheran', 'mindless', 'nintendo',\n",
              "       'pentecostals', 'pyrtech', 'retaliate', 'scribe', 'somesuch',\n",
              "       'surrounds', 'tpinnpcn', 'utai', 'winadv'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfziBV3ZhQZu"
      },
      "source": [
        "# Filtering by Document Frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59gqHKvWhVAd"
      },
      "source": [
        "Two corner cases to consider:\n",
        "* a word appears in nearly all documents: does not participate actively to make a difference between documents\n",
        "* a word appears only in 1 or 2 documents: same. It is likely a typo, or an artefact\n",
        "\n",
        "Use the `min_df` and `max_df` arguments.\n",
        "* `min_df=3` words that appear in more than 3 documents will be in the vocabulary\n",
        "* `min_df=0.1` words that appear in more than 10% of the documents will be in the vocabulary\n",
        "* `max_df=10` words that appear in less than 10 documents will be in the vocabulary\n",
        "* `max_df=0.9` words that appear in less than 90% of the documents will be in the vocabulary\n",
        "\n",
        "Typical usage:\n",
        "* `min_df=2`\n",
        "* `max_df=0.8`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Rky9YkgixK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80981e86-f983-4add-d65b-b32c5fc24f52"
      },
      "source": [
        "count = CountVectorizer(\n",
        "    stop_words=stops,\n",
        "    token_pattern=r'[a-z]+\\w*',\n",
        "    max_features=50000,\n",
        "    min_df=5,\n",
        "    max_df=0.8\n",
        ")\n",
        "count.fit(newsgroups.data)\n",
        "\n",
        "vocab_df = count.get_feature_names_out()\n",
        "print(f'Size of vocabulary: {len(vocab_df)}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 23726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8dVXsImi1im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ddfae10-3fb2-47d6-ed87-7d11d604bd49"
      },
      "source": [
        "print(' '.join([f'{w:<10}' for w in vocab_top[:10]]))\n",
        "print(' '.join([f'{w:<10}' for w in vocab_df[:10]]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aa         aaa        aaaarrgghhhh aaah       aaahhhh    aaai       aab        aachen     aad        aaf       \n",
            "a0         a000       a1         a137490    a2         a2i        a3         a4         a42dubinski a5        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAxMEcmGjtw9"
      },
      "source": [
        "# Stemming / Lemmatizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeOAvg00nZxw"
      },
      "source": [
        "## Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meyW1vc7jvmC"
      },
      "source": [
        "Both of them are a process applied to a word, that reduces it to its stem. Plurals are reduced to singular, etc...\n",
        "\n",
        "* Lemma: is a word that exists\n",
        "* Stem : might not be a word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9NKnivRlZyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2191526d-0a07-4332-f4c7-59744802257d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjvLbVRti5Gj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df51eed-4738-44f4-fd40-6eea8f696e5e"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "wn = WordNetLemmatizer()\n",
        "ps = PorterStemmer()\n",
        "\n",
        "word = 'horses'\n",
        "\n",
        "print(f'Word: \"{word}\", PorterStemmer: \"{ps.stem(word)}\", WordNetLemmatizer: \"{wn.lemmatize(word)}\"')\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: \"horses\", PorterStemmer: \"hors\", WordNetLemmatizer: \"horse\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8IN6Di2YA1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55017bb4-cd60-4a41-8df7-4a527e710f8e"
      },
      "source": [
        "word = 'horse'\n",
        "\n",
        "print(f'Word: \"{word}\", PorterStemmer: \"{ps.stem(word)}\", WordNetLemmatizer: \"{wn.lemmatize(word)}\"')\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: \"horse\", PorterStemmer: \"hors\", WordNetLemmatizer: \"horse\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcL-gCu9mTKr"
      },
      "source": [
        "It is not important that the stem is not an actual word from the dictionary, as long as all the times we see either form of the word ('horses' or 'horse') it is counted under the same dimension, that will correspond to 'hors' or 'horse'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lPJe2MRncqv"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsHnURQlneSH"
      },
      "source": [
        "Let's make an example on the Sherlock Holmes book \"Scandal in Bohemia\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk_zcHl9nr4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951cd1a2-d255-4284-8463-8d33adfecc34"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmZ_WT3bnirP"
      },
      "source": [
        "import requests\n",
        "\n",
        "r = requests.get('https://sherlock-holm.es/stories/plain-text/scan.txt')\n",
        "r.raise_for_status()\n",
        "\n",
        "with open('scandal_in_bohemia.txt', 'w') as out:\n",
        "    out.write(r.content.decode('utf-8'))\n",
        "lines = [txt for txt in open('scandal_in_bohemia.txt') if len(txt.strip()) > 0]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w04R9xbOqjJ1"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "book = ' '.join([x.strip() for x in lines])\n",
        "sentences = sent_tokenize(book)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6JyALGskJDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "3c1942b9-485f-4225-dfea-a1ffee846ac9"
      },
      "source": [
        "count_vanilla = CountVectorizer()\n",
        "count_vanilla.fit(sentences)\n",
        "\n",
        "tokenizer = CountVectorizer().build_tokenizer()\n",
        "\n",
        "wn = WordNetLemmatizer()\n",
        "def lemmatizer(text):\n",
        "    tokens = tokenizer(text)\n",
        "    return map(wn.lemmatize, tokens)\n",
        "\n",
        "count_lemma = CountVectorizer(\n",
        "    tokenizer=lemmatizer,\n",
        ")\n",
        "count_lemma.fit(sentences)\n",
        "\n",
        "ps = PorterStemmer()\n",
        "def stemmer(text):\n",
        "    tokens = tokenizer(text)\n",
        "    return map(ps.stem, tokens)\n",
        "\n",
        "count_stem = CountVectorizer(\n",
        "    tokenizer=stemmer\n",
        ")\n",
        "count_stem.fit(sentences)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(tokenizer=<function stemmer at 0x7f1dcf9abce0>)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(tokenizer=&lt;function stemmer at 0x7f1dcf9abce0&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(tokenizer=&lt;function stemmer at 0x7f1dcf9abce0&gt;)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhGo2F1rrV3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28dce493-b5cc-47ef-9bf3-d91207be0c43"
      },
      "source": [
        "words_vanilla = set(count_vanilla.get_feature_names_out())\n",
        "words_lemma = count_lemma.get_feature_names_out()\n",
        "words_stem = count_stem.get_feature_names_out()\n",
        "\n",
        "removed_by_lemma = words_vanilla.copy()\n",
        "for w in words_lemma:\n",
        "    removed_by_lemma.discard(w)\n",
        "\n",
        "removed_by_stem = words_vanilla.copy()\n",
        "for w in words_stem:\n",
        "    removed_by_stem.discard(w)\n",
        "\n",
        "print(f'{len(removed_by_lemma):>4d} words removed by lemmatizer')\n",
        "print(f'{len(removed_by_stem):>4d} words removed by stemmer')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 182 words removed by lemmatizer\n",
            "1024 words removed by stemmer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fw_CL2Huc9R"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "This plays a major role in aligning the cosine similarity with the human evaluation of similarity.\n",
        "\n",
        "Consider two sentences and how their cosine similarity evolve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwWVel2bsOC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee17da5-b1b7-4dbe-efe0-8a8232eb487d"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "text_01 = 'it is hard to make a horse look good'\n",
        "text_02 = 'I like making horses looking good'\n",
        "\n",
        "for name, vectorizer in zip(['Vanilla', 'Lemma', 'Stem'], [count_vanilla, count_lemma, count_stem]):\n",
        "    bows = vectorizer.transform([text_01, text_02])\n",
        "    similarity = cosine_similarity(bows)\n",
        "    print(f'{name:<8}: Cosine Similarity = {similarity[0, 1]:0.2f} with {bows.shape[1]:>4d} dimensions')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla : Cosine Similarity = 0.17 with 1948 dimensions\n",
            "Lemma   : Cosine Similarity = 0.32 with 1852 dimensions\n",
            "Stem    : Cosine Similarity = 0.63 with 1647 dimensions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7njPU4q45d11"
      },
      "source": [
        "## Stemmers / Lemmatizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DknaO7G75hv0"
      },
      "source": [
        "There are many types of stemmers and lemmatizers:\n",
        "* Stemmers\n",
        "   * Snowball\n",
        "   * Porter\n",
        "   * Lancaster\n",
        "   * Regexp\n",
        "* Lemmatizers\n",
        "   * WordNet\n",
        "   * StanfordCore NLP\n",
        "\n",
        "Each has its own algorithm for reducing a word to a stem or lemma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ1RSiRaVr5b"
      },
      "source": [
        "# N-Grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ_7sgvSVt2g"
      },
      "source": [
        "## Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOqkKe4LVwkS"
      },
      "source": [
        "So far we have considered a vocabulary made of words, like `turtle` or `airplane`, or of stems like `hors` and `make`.\n",
        "\n",
        "N-Grams are groups of N consecutive words in the text.\n",
        "\n",
        "For example, in the sentence `the cat is gone`, the 2-grams are `the cat`, `cat is`, `is gone`.\n",
        "\n",
        "The production of N-Grams is controled by the parameter `n_grams` in sklearn CountVectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9voixaKIdD7o"
      },
      "source": [
        "## Importance of N-Grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3ZUQvNAdGtW"
      },
      "source": [
        "Bag of Words vectors ignore word order in a sentence. But it makes sense that some information is communicated through some words being side-by-side rather than these words being in the sentence.\n",
        "\n",
        "It carries more information to know that `new york` is in a sentence, opposed to knowing that both `new` and `york` are in the sentence, without knowing that they are side by side.\n",
        "\n",
        "The most frequent 3-Gram over the English Internet is 'Limited Liability Corporation'. This 3-gram has a meaning, and if the same 3-gram can be found in 2 sentences, they share more similarity than if those 3 words occur in both sentences.\n",
        "\n",
        "Similarity = Cosine similarity of BoW. It justifies having a dimension of the BoW vectors that encodes the facts that some words are side-by-side."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWm31-3wWQ9p"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6GC0-xHWlcL"
      },
      "source": [
        "We use Sherlock Holmes once again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiV5xmYkYMkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efcc0955-309c-4088-f563-6e70ddb3a09c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-uUj0wUWjwM"
      },
      "source": [
        "import requests\n",
        "\n",
        "r = requests.get('https://sherlock-holm.es/stories/plain-text/scan.txt')\n",
        "r.raise_for_status()\n",
        "\n",
        "with open('scandal_in_bohemia.txt', 'w') as out:\n",
        "    out.write(r.content.decode('utf-8'))\n",
        "lines = [txt for txt in open('scandal_in_bohemia.txt') if len(txt.strip()) > 0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vuVqaLSWjwM"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "book = ' '.join([x.strip() for x in lines[7:]])\n",
        "sentences = sent_tokenize(book)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpQXNUvKX-Uk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "708f700d-68f9-41f5-efe8-a104c37edb40"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),    # will create a vocabulary with 1-gram and 2-grams\n",
        "    min_df=2,\n",
        "    max_df=0.8,\n",
        "    max_features=1500\n",
        ")\n",
        "\n",
        "count.fit(sentences)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(max_df=0.8, max_features=1500, min_df=2, ngram_range=(1, 2),\n",
              "                stop_words='english')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_df=0.8, max_features=1500, min_df=2, ngram_range=(1, 2),\n",
              "                stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(max_df=0.8, max_features=1500, min_df=2, ngram_range=(1, 2),\n",
              "                stop_words=&#x27;english&#x27;)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwIe_iq8Y9jA"
      },
      "source": [
        "show_vocabulary(count, word_size=25, words_per_line=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCGqxtIKZAKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280c957e-2492-4139-98b1-14896d51025c"
      },
      "source": [
        "N = 0\n",
        "bow = count.transform([sentences[N]]).toarray()[0]\n",
        "print(f'\"{sentences[N]}\"')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"To Sherlock Holmes she is always the woman.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLb2RgfGcTvw"
      },
      "source": [
        "show_bow(count, bow, word_size=25, words_per_line=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTPqDmqWayk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f68fbe0-044a-4ab9-c811-2b10ca541865"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "texts = {\n",
        "    'Text 01': sentences[0],\n",
        "    'Text 02': 'Sherlock is a good Holmes man',\n",
        "    'Text 03': 'Sherlock Holmes is a good man'\n",
        "}\n",
        "\n",
        "bows = count.transform(texts.values())\n",
        "similarity = cosine_similarity(bows)\n",
        "\n",
        "sim_df = pd.DataFrame(similarity, columns=texts.keys(), index=texts.keys())\n",
        "\n",
        "for k, v in texts.items():\n",
        "    print(f'{k:<10}: \"{v}\"')\n",
        "print()\n",
        "print(sim_df)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 01   : \"To Sherlock Holmes she is always the woman.\"\n",
            "Text 02   : \"Sherlock is a good Holmes man\"\n",
            "Text 03   : \"Sherlock Holmes is a good man\"\n",
            "\n",
            "         Text 01   Text 02   Text 03\n",
            "Text 01  1.00000  0.500000  0.670820\n",
            "Text 02  0.50000  1.000000  0.894427\n",
            "Text 03  0.67082  0.894427  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4TWKt1IgJzq"
      },
      "source": [
        "# New definition for Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSOoLplggP0F"
      },
      "source": [
        "Our vocabulary does not contain only *words*, as we see that we can stem or lemmatize these words, and also identify groups of them that repeat. To avoid confusion, we no longer consider the vocabulary to be made of words, but of terms.\n",
        "\n",
        "**Term**:\n",
        "* a single word (`turtles`)\n",
        "* a lemma or a stem of a single word (`turtl` or `turtle`)\n",
        "* consecutive words or lemmas or stems (`sea turtle` or `sea turtl`)\n",
        "\n",
        "The **Vocabulary** is the set of unique **terms** that appear in the text:\n",
        "* `turtle` `sea` `sea turtle`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g7LU1t-enAE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}